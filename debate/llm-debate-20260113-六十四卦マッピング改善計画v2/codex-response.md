# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
改善計画v2は「機械学習の実験計画」としては形になっているが、「六十四卦マッピング改善計画」としては不合格である。最大の欠陥は、**64卦というラベルの意味定義と、爻（段階）定義が易経の対象と整合していない**まま、評価指標（κ/F1）だけで成功を宣言できる構造になっている点である。

### 批判的分析
#### 1) 論理的整合性（矛盾）
- **「易経意味論は後から」→ 64卦ラベル体系が空中分解する。**  
  64卦は本質的に意味論的カテゴリであり、「易経らしさ」を棚上げしても、結局は各卦が何を指すかを規定しない限りアノテーションが成立しない。本計画は「再現可能なラベル体系」を掲げつつ、肝心のラベル（64卦）の操作的定義を提示していない。
- **「爻＝汎用プロセス段階」はカテゴリ誤りである。**  
  爻を「情報収集→計画→実行→転換→成熟→終末」の一般工程で固定するのは、六爻が持つ卦ごとの文脈依存の推移を破壊する。結果として「同じ段階でも卦によって意味が逆転する」現象を無視し、整合性は取れない。
- **unknown（真のラベル）と reject（モデルの棄却）を混同している。**  
  Step1のunknownは「入力が足りない／段階不特定」というデータ側の属性である。一方、Step5の閾値棄却はモデル側の行動である。これを同じ「unknown」に寄せると、評価が破綻する（unknownを当てたのか、逃げたのかが区別不能）。

#### 2) 実現可能性（コスト見積もりが誤り）
- **時間見積もりが現実と一致しない。**  
  64卦×3件＝192件を「2名独立」で作る時点で最低384判断＋不一致裁定が発生する。1判断を1〜2分で安定して64卦＋爻まで決める前提自体が無理である。8–12hは成立しない。ガイドライン3–4hも、64カテゴリ＋境界例＋禁止事項を整備する作業量と釣り合わない。
- **20件パイロットでκ≥0.7は統計的に無意味である。**  
  20件ではκの分散が大きすぎ、改善・劣化の判定に使えない。「目標値を置いた」以上の意味がない。

#### 3) 新規性の真偽（何が新しいのか）
- 本計画の骨格（ガイドライン→パイロット→ゴールド→評価→校正）は標準手法であり新規性はない。新しいのは「易経ドメインに査読可能な評価手順を持ち込む」点だけである。新規性を主張するなら、**64卦を分解して再現可能にする表現設計**（後述）が必要である。

#### 4) スケーラビリティ（拡張不能な設計）
- 2名手作業＋裁定は200件で限界が来る。1000件に増やすと運用が崩壊する。スケールさせるなら、**階層化（8→64）**、**候補提示（Top-k）**、**能動学習（難例優先）**、**プロトタイプ検索**を計画段階から組み込む必要がある。

#### 5) 反例・エッジケース（ここで破綻する）
- 1入力に複数の「契機/行動/段階」が混在する叙述（回想・並列・転機の連続）は、単一ラベル前提だと必ず破綻する。  
- 「行動が語られていないが状況は濃い」「契機はあるが本人の意思決定がない」など、unknownに落とすか無理割当するかで体系が歪む。unknown条件が粗いままだとデータがunknownに吸われ、実用にならない。  
- 爻を汎用工程に固定すると、「初爻が終末」「上爻が開始」に相当するテキストが大量に発生し、解釈レイヤ以前にラベルが崩れる。

#### 6) 代替案との比較（より優れた設計が存在する）
- 64クラス直当てより、**（上卦・下卦）を別々に当てる二段推定**の方が一致度もモデル性能も上がる。64＝8×8なので分解の利益が大きい。  
- 「分類」より「検索＋比較」が適する。入力に近い典型例（プロトタイプ）を検索し、候補卦をTop-kで提示して最終判定する方が、再現性と説明責任が両立する。

### Claudeの意見への反論/修正
- 正しい点：  
  - **強制割当の廃止（unknown許可）**、**ガイドライン整備**、**独立アノテーション**、**外部（少なくとも保持アウト）での評価**は必須であり、方向性は正しい。
- 誤りである点：  
  - **「爻＝プロセス段階」定義は易経の対象と一致しない。** この定義を採用した瞬間に「六十四卦マッピング」ではなく「汎用プロセス分類」になる。  
  - **F1≥0.7を前提に意味論検証を後回しにするのは順序が逆である。** 意味が壊れたラベルでもF1は上がる。高F1は正しさの証明にならない。  
  - **20件でκ≥0.7目標は評価設計として成立しない。** 目標値が工程管理の飾りになっている。  
  - **「confidence校正」は自己申告スコア前提だと破綻する。** LLMの自己申告confidenceは確率ではない。校正以前に定義が必要である。

### より正確な見解
この計画を成功させる鍵は、指標や手順ではなく **「64卦・爻を再現可能にする表現設計」**である。修正案は以下である。

1. **出力仕様を先に確定する**  
   - 例：`hexagram_id (1..64)`, `moving_line (1..6 or none)`, `abstain (true/false)`, `evidence_span`, `confidence`  
   - `unknown`は「データとして判定不能」の真ラベル、`abstain`は「モデル行動」として分離する。

2. **64卦を階層・分解して定義する（必須）**  
   - 直接64当てをやめ、まず`upper_trigram (1..8)`と`lower_trigram (1..8)`を別々に判定する。  
   - その上で64卦へ合成し、最終段で同名混同（似た卦）を解く。これが再現性と精度を同時に上げる。

3. **爻の定義を「汎用工程」から撤退させる**  
   - 爻は卦ごとに進行意味が異なるため、「卦別の爻コードブック」を作る。  
   - どうしても共通尺度が必要なら、爻は`early/mid/late`程度の粗い三段階に落とす。6段階の順序尺度を全卦で強制する設計は誤りである。

4. **評価設計を「正解率」一本から変える**  
   - Top-1だけでなくTop-3（候補提示）を評価対象にし、`coverage（棄却しない割合）-accuracy`の曲線で運用点を決める。  
   - κは工程の健康診断として使い、成功基準は「ユーザー用途での失敗コスト」に結びつける。

5. **データ設計を現実サイズにする**  
   - 64×3＝192は「初期の動作確認」止まりであり、性能評価には不足である。  
   - 最低でも各卦10例規模（640）＋難例集を別枠で持たない限り、F1や校正の議論は成立しない。

この修正を入れない限り、v2は「測れているように見えるが、対象（六十四卦）を測っていない」計画として終わる。修正後なら、再現性と易経としての意味の両方を査読可能な形で前進させられる。
