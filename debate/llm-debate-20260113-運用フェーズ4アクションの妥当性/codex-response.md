# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
この運用フェーズ4アクション計画は、方向性は理解できるが**現状のままでは妥当ではない**。理由は、(i) **KPI定義が誤っている**（Unknown率を目標化する設計が破綻）、(ii) **評価指標が成立していない**（ECE/Brierの前提が欠落）、(iii) **「Wikipedia降下」が証拠化になっていない**（外部リンク抽出＝根拠獲得ではない）、(iv) **人手工数見積が構造的に過小**で、実行しても再現性ある成果に収束しないからである。

### 批判的分析
#### 1) 論理的整合性（前提・定義が壊れている）
- **Unknown率=悪という前提が誤りである。**「unverifiable」は世界の性質であり、運用で消せるノイズではない。Unknown率を下げる最短経路は「検証しやすい事例だけを選別する」ことであり、これはデータの代表性を破壊してモデル評価と運用判断を誤らせる。
- **Proper Scoring Rule（ECE/Brier）の計画が成立していない。**Brier Score/ECEは「確率予測」が前提である。計画には「各事例に対する予測確率（いつ・誰が・どのモデルが出したか）」が存在しない。したがって「完了後にECE/Brier計算」は現時点で虚偽の工程である。
- **ラベル設計が重複・矛盾している。**  
  - `outcome_verified: correct/incorrect/unverifiable` と `factual_accuracy: accurate/minor_error/major_error/unverifiable` は概念が衝突する。例えば「minor_errorだが結論はcorrect」の許容範囲が未定義で、ラベラー間の不一致を確実に増やす。  
  - `source_quality` のカテゴリ（primary/secondary/tertiary/unreliable）と、後段で使う `tier1/tier2`、Action2の `primary/secondary/other` が混在し、スキーマが運用上の単一言語になっていない。
- **依存関係の設計が甘い。** Action2の出力（リンク分類）は、Action1の「何を根拠と認めるか」という定義が固まっていないと価値が測れない。順序を「自動化だから先」で決めるのは運用計画として幼稚である。

#### 2) 実現可能性（隠れたコストを無視している）
- **Action1（500件二重ラベリング300h）は過小見積である。**  
  15分/件は「ソース探索・本文確認・矛盾解消・記録・根拠URLの保存・判断理由の要約」を含めると成立しない。さらに、ラベラー教育、ガイドライン整備、ツール整備（入力UI/差分比較/監査ログ）、QA再ラベリングが必須で、ここが0時間扱いになっている時点で見積の信頼性がない。
- **不一致20%は根拠がない。** この種の複合ラベル（正誤＋ソース品質＋COI＋誤差程度）は、初期は不一致が高くなる。20%前提で工程を組むのは失敗の原因である。
- **Action2（Wikipedia 16h）は「実装時間」しか見ていない。** 外部リンクの正規化（重複排除、リダイレクト追跡、追跡パラメータ除去）、ドメイン辞書の保守、レート制限、キャッシュ、失敗再試行、そして「そのリンクが当該主張の根拠か」の検証が未計上である。最も重いのは後者であり、ここが抜けている。
- **Action4（750h）は組織能力の前提が欠落している。** 4,500件×10分は「読み込み不要で機械的に判定できる」前提だが、検証は根拠読解が中心である。10分前提は成り立たない。

#### 3) 新規性の真偽（新しくない）
- 4アクションは「評価セット作成」「Wikipediaから外部リンク抽出」「主張アノテーション」「未検証の追加検証」であり、**データ品質運用の定番**である。新規性はゼロである。新規性を主張するなら「既存手法と比べて何が速く・安く・正確か」を定量で示す必要があるが、計画には存在しない。

#### 4) スケーラビリティ（人手前提で破綻）
- 500件二重＋100件主張抽出＋4,500件検証は、**拡大すればするほど品質が落ちる典型構造**である。人手の増員はIAAを下げ、調停コストを指数的に増やす。  
- Action2も「リンクが増えるほど手動検証が増える」ため、外部リンクを掘るだけではスケールしない。証拠化（claim↔citation紐付け）を自動化しない限りボトルネックは解消しない。

#### 5) 反例・エッジケース（計画が破綻する典型）
- **そもそも検証不能**：一次資料が存在しない、非公開、口頭伝聞のみ、時間依存（更新される統計）、定義が曖昧（「有名」「多い」）。Unknownを減らす目標はここで必ず破綻する。
- **Wikipedia外部リンクの罠**：外部リンクは参考・関連リンクであり、主張の根拠ではない。さらに、リンク切れ・アーカイブ・誘導ページ・商用サイト・SNSが混ざる。分類しても「証拠」にならない。
- **主張抽出の境界問題**：1事例3–5主張という固定は誤りである。事例によって主張数は0にも20にもなる。固定本数は情報を捏造する行為であり、後段モデルを汚染する。
- **COI判定の非再現性**：COIは「推測」と「証拠」が混ざりやすい。ガイドラインと証拠要件が無いCOIラベルはノイズ生成器である。

#### 6) 代替案との比較（より優れた設計が存在する）
この計画の欠陥は「量をKPI化」して「証拠化を未実装」のまま人手を投入する点にある。代替は以下である。
- **KPIをUnknown率から“検証可能集合での被覆率”に置換**：  
  `Unknown` を「検証不能理由つき」に分解し、目標は `verifiable_cases_coverage` と `evidence_completeness` にする。Unknown率50%は廃棄が正しい。
- **Action1は“500件二重”の前に30–50件の設計スプリントが必須**：  
  まず定義を固め、各フィールドのIAAを個別に測定し、COIなど低再現フィールドは削る。これをしない500件二重は時間を燃やすだけである。
- **Action2は externallinks 抽出ではなく“引用（citation）抽出＋主張紐付け”が本体**：  
  「リンクを拾った」ではなく「この主張はこの引用で支えられる」をデータ化する。降下成功率は“関連一次/二次根拠が主張に紐づいた比率”で定義し直す。
- **Action4は4,500件手作業ではなく“選別と自動補助”が本体**：  
  価値が高い（頻出・コア主張・影響大）事例を優先し、機械で根拠候補を提示→人が最終判断、という形に変える。人手で全文検索・読解を毎回やる設計は破綻する。

### Claudeの意見への反論/修正
- 「自動化できるWikipediaを先行」は**工程都合の最適化であり、品質最適化ではない**。外部リンク抽出は証拠化ではないので、先にやってもKPIが改善した“気分”しか得られない。Action2を先行するなら「引用紐付けの正解率評価」を同時に入れる必要がある。
- 「評価セット二重ラベリングでKPI基盤」は方向として正しい。しかし、**ECE/Brierを出す前提（確率予測ログの固定）が欠落**している点を見落としている。ここは計画上の致命傷である。
- 「Unknown率50%」目標を妥当として扱っているのは誤りである。Unknownは削減対象ではなく、分類して管理すべき状態である。

### より正確な見解
本質は「Unknownを減らす」ではなく、**(1) 検証の定義を固定し、(2) 主張と根拠を機械可読にし、(3) 評価指標が成立するログとデータを作る**ことである。したがって運用フェーズは次の形に再設計すべきである。
1. **定義と計測の確立（最優先）**：ラベル間の整合性（correct/incorrectとminor/majorの関係）を規約化し、IAA指標（どの係数か）と合格基準をフィールド別に設定する。ECE/Brierを使うなら予測確率ログを固定する。  
2. **Wikipediaは“引用→主張”の証拠グラフ化に限定**：外部リンク収集ではなく、主張を支える引用を構造化して初めて降下が価値を持つ。  
3. **主張タグ付けは測定設計込みで小さく始める**：抽出境界の一致率（スパン/F1）とコア主張一致率を測る。固定本数ルールは廃棄する。  
4. **スケールは人手総量ではなく情報利得で回す**：4,500件検証は目標から外し、「高価値事例の検証被覆率」「根拠完備率」「再現性（IAA）」をKPIに置く。

この修正なしに現計画を実行する行為は、時間と信頼性を同時に失う。
