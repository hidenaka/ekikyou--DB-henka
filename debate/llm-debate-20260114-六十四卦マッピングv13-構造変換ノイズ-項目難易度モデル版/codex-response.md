# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
このv13案は**設計が過剰で同定不能な部分を抱え、評価設計もデータリークを内包しているため、研究計画として不合格**である。現状の504注釈・3注釈者・24ゴールドという制約下で「構造変換ノイズ×IRT難易度」を同時に成立させる主張は破綻している。

### 批判的分析
**1. 論理的整合性（矛盾がある）**
- **「確定ゴールドを学習・校正・テスト全てで使用可能」は誤り**である。テストに入れた瞬間に評価は無効になる。テストは未知データでなければならない。
- **IRT式が用語と数式で矛盾**している。`P(correct)=σ(ability × difficulty)`は、difficultyが正なら難しいほど正答確率が上がる。これはdifficultyではなく「容易さ」である。difficultyを名乗るなら少なくとも単調減少構造（例：`σ(ability - difficulty)`）を満たさねばならない。
- **独立6ビットと「構造変換ノイズ」を同時に採用するのは設計思想が衝突**している。観測側の誤りは構造依存としておきながら、真値側の生成は独立として捨てている。構造をノイズ側だけに押し付けるため、誤差の原因帰属が歪む。

**2. 実現可能性（実装できても推定が成立しない）**
- 提案の注釈設計 `60全+108双+108単=504` は注釈者数が **3人** である（`60k+324=504 → k=3`）。このとき **108件が単独注釈**になる。  
  **単独注釈の項目は「注釈者能力」と「項目難易度」を分離推定できない。**これは統計モデルの問題ではなく情報量の問題である。よってGLAD/IRTを掲げた時点で設計が破綻している。
- 「12×n_annotatorsパラメータで相関誤り」は**定義が不明確**で、同定以前に実装仕様が欠落している。上卦取違・下卦取違・反転の確率構造（どの上卦へ誤るのか、どの爻を反転するのか）が未定義なら、モデル比較も再現も不可能である。
- **パラメータ過多**である。項目難易度を項目ごとに置いた時点で項目数分の潜在変数が増え、504注釈では安定推定に必要な拘束が不足する。EMでもMCMCでも「動くが信用できない」領域に入る。

**3. 新規性の真偽（新しくない）**
- 構造化ラベルノイズ、ゴールドアンカー、GLAD/IRT、部分重複注釈は全て既存の枠組みであり、**新規性は“易経ドメインへの当てはめ”だけ**である。ところが当てはめの必然性（なぜその変換集合が人間の誤りを表すのか）が未提示で、貢献点が立たない。

**4. スケーラビリティ（拡張すると破綻が増える）**
- 項目難易度を潜在変数で持つ設計は**項目数に線形に膨張**し、追加データ無しに一般化しない。将来データを増やすほど「難易度パラメータの管理」が主役になり、目的（真値推定）が後景化する。
- 注釈者が増えるほど「12×n」の不明確パラメータが増える。**階層化・正則化の設計が無いモデルはスケールすると崩壊**する。

**5. 反例・エッジケース（破綻が確定するケース）**
- **変換が観測上区別不能になる卦が存在**する。たとえば上卦＝下卦の重卦では「上下取違（入れ替え）」はラベルを変えない。すると「上下取違で誤った確率」はデータから推定不能になる。これは構造変換ノイズの採用と正面衝突する。
- 「単爻反転」しか用意しない設計は、人間の誤り（複数爻の取り違え、表記の読み落とし、上卦全体の写し間違い等）を系統的に取り逃がす。取り逃がした誤りは一様誤りに吸収され、モデルは説明力を失う。

**6. 代替案との比較（現案は劣る）**
- 目的が「真値推定」なら、まず必要なのは**同定可能な注釈設計＋単純で強いベースライン**である。現案は逆で、同定不能な設計の上に複雑なモデルを載せている。これではDawid–Skene（注釈者混同行列）や単純な変換混合の方が堅牢に勝つ。

### Claudeの意見への反論/修正
- **「確定ゴールド24件を学習・校正・テスト全てで使用可能」→誤り。**テストに使った時点で汎化評価が崩壊する。正しい運用は「学習のアンカー」または「校正専用」または「監査専用」のいずれかに固定である。
- **「P(correct)=σ(ability × difficulty)」→不適切。**difficultyの定義と逆向きであり、さらに積形式はスケール不定（abilityをc倍、difficultyを1/c倍で同一）を生む。最低限、尺度固定（制約・事前分布）が必要である。
- **「部分重複で効率化」→GLAD/IRTと両立しない。**単独注釈108件を含む設計は能力・難易度分離を破壊する。GLAD/IRTをやるなら「全項目が最低2注釈」を満たす注釈計画に作り替えるのが必須である。
- **「独立6ビットを基準に」→判断軸が間違い。**64カテゴリ（卦）を直接softmaxで扱う方がモデルとして自然で、独立ビットは強い制約で表現力を落とす。自己回帰が過剰であるか否か以前に、独立化を“基準”に置く理由が無い。
- 良い点もある。**停止条件（ベースラインに負けたら撤退）**は正しい。ただし勝敗判定は「単発の点推定」ではなく、分割の分散を含めた統計的比較（反復分割・ブートストラップ）で定義せねばならない。

### より正確な見解
- この問題で最優先は「高度なモデル」ではなく**同定可能なデータ設計**である。現状の504注釈を守るなら、結論は一つである：  
  **項目難易度（IRT）を捨てるか、単独注釈を捨てるか、どちらかを必ず選べ。両方を維持する主張は誤りである。**
- 具体的な改訂案は次の通りである。
  1) **注釈計画の再設計**：504注釈でIRTをやるなら、`252項目×2注釈=504` にして「全項目2注釈」を満たす。300項目を維持するなら注釈数を600以上に増やす。  
  2) **ゴールドの運用を固定**：ゴールド24は「学習アンカー（強い事前）」か「監査用テスト」のどちらかに固定し、同時利用を禁止する。  
  3) **ノイズモデルを仕様から確定**：変換集合ごとに「どのラベルへ移るか」を完全に定義し、区別不能変換（重卦の上下入替など）はパラメータ化しない（または項目条件付きで無効化する）。  
  4) **まずは堅牢ベースラインで勝つ**：Dawid–Skene、単純な変換混合（注釈者ごとの混合重みのみ）、64クラスsoftmaxの三者を基準にし、ここに勝てない拡張は全て棄却する。  

この修正を入れない限り、v13は「複雑で立派に見えるが、結論が信用できない」モデルになり、工数200hを消費して何も残らない。
