# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
このv14最終設計は**「厳密な最終評価」も「Dawid–Skeneで64クラス同定」も成立していない破綻案である**。理由は単純で、**(a) 64×64混同行列を552注釈で推定する設計が情報量的に不可能**、かつ **(b) テストの正解定義が欠落しており評価が循環**しているからである。

---

### 批判的分析

#### 1) 論理的整合性（主張と根拠の矛盾）
- **「同定可能性」を掲げながら、最も同定不能な設定を採用している。**  
  64クラスDawid–Skeneで各注釈者の混同行列は **64×64=4096セル**。注釈者3名なら **4096×3=12,288セル**（＋クラス事前）。一方、総注釈は **552**。セル当たり観測は平均 **552/12,288=0.045**。これは推定ではなく空想である。  
  「スパース正則化で制御」と言っても、**観測がないセルは“ゼロにするしかない”だけ**であり、推定が信用できる状態にならない。
- **「GLAD/IRTはパラメータ過多で却下」→DS(64×64)の方が桁違いにパラメータ過多である。**  
  却下理由が自己矛盾している。DSはこの設定では「古典的で堅牢」ではなく「古典的で無謀」になる。

#### 2) 実現可能性（技術・実務）
- **EMが収束しても推定値が無意味になる。**  
  収束は「正しい推定」の証拠ではない。観測が足りない多クラスDSは、正則化と初期値で都合よく決まった行列に収束するだけである。
- **2注釈/項目はDSの“最低条件”ですらない。**  
  2注釈は単に「多数決が成立する」だけで、**混同行列を安定推定する冗長性が不足**する。設計として必要なのは「各注釈者ペアの十分な重複」「各クラスの十分な出現」「3者同時注釈の塊」である。提示案はこの設計が欠落している。
- **64クラスSoftmax学習データ190件（166+Gold24）は成立しない。**  
  64クラス分類は最低でも「全クラスが訓練で観測される」ことが必要条件。190件では**未観測クラスが必ず発生**し、そのクラスは学習不可能である。DSの事後分布を教師にしても、**存在しない情報は増えない**。

#### 3) 新規性の真偽
- **新規性はない。**  
  DS＋soft-label学習＋温度スケーリング＋ベースライン比較は、機械学習実務の既製品の寄せ集めである。新規性を主張するなら「六十四卦という対象の特性を利用した構造化設計」が必要だが、本案はそれを捨てている。

#### 4) スケーラビリティ
- **スケール“アップ”には耐えるが、提示スケール（小規模）では破綻する。**  
  DSのKクラス混同行列はパラメータが **O(K²)**。K=64は小さく見えるが、**データが276項目しかない時点で致命的**。  
  逆にデータが数万項目に増えるなら動くが、それは「この設計でいける」根拠ではなく「データを増やせば古典手法が動く」という当たり前である。

#### 5) 反例・エッジケース（破綻する状況）
- **真値が一意でない問題を強制的に一意にする。**  
  六十四卦マッピングが解釈依存・文脈依存で複数解を許すなら、DSは「注釈者の多数派」を真値に固定し、少数派解釈を誤りとして潰す。これはタスク定義の破壊である。
- **注釈者が同じガイドラインに引きずられて相関するケースでDSは壊れる。**  
  DSは（条件付きで）注釈誤りの独立性を暗黙に仮定する。実務では誤りは相関する。相関誤りをDSは説明できず、混同行列に歪みとして吸収して偽の“能力差”を作る。

#### 6) 代替案との比較（より優れた手）
- このデータ規模なら、**64クラスを直接扱う設計自体が誤り**である。代替の勝ち筋は「構造を使ってクラス空間を圧縮」することに尽きる。

---

### Claudeの意見への反論/修正
- **正しい点**  
  - 「シンプル優先」「テスト汚染禁止」は方向性として正しい。  
  - 「注釈設計が先」「ベースラインに負けたら撤退」も正しい態度である。
- **誤り（致命傷）**  
  - **「Dawid–Skeneは古典的で堅牢」→この設定では堅牢ではない。** 64×64混同行列を552注釈で推定するのは不可能であり、堅牢性以前の問題である。  
  - **「全項目2注釈以上＝同定可能性の基本要件」→誤りである。** 同定可能性は「注釈数」ではなく「重複設計・クラス被覆・情報量」で決まる。2注釈は多数決要件でありDS要件ではない。  
  - **「ゴールド24件は学習アンカー専用、テストに含めない」→誤りである。** “テストにゴールドを含める”こと自体は評価の王道であり、禁じるべきは「テストゴールドを学習や温度調整に使うこと」だけである。テストに専門家ゴールドが存在しない評価は厳密にならない。  
  - **「八卦×3件でアンカー」→64クラスの置換対称性を解消できない。** 8カテゴリ相当のアンカーでは64クラス同定のアンカーとして不足している。

---

### より正確な見解
- **この問題の本質は「モデル選択」ではなく「タスク定義とデータの情報量設計」である。**  
  まず決めるべきは「何を正解とするか」だ。専門家合議の正解を目標にするなら、**テストセットに専門家ゴールドが必須**である。注釈者の多数派を目標にするなら、評価は「注釈者再現」であり「真理」ではないと明記しなければならない。
- **552注釈でやるべき設計は64クラスDSではない。**  
  現実解は次のいずれかに限られる。  
  1) **クラス空間を縮約**：六十四卦＝上卦8×下卦8として、まず上卦・下卦の2段（8クラス×2）に落とす。DSも8×8で推定する。  
  2) **構造化出力**：6ビット独立ではなく、共有表現＋制約付きで6爻を予測し、64への射影で整合性を担保する。  
  3) **データを増やす**：64クラスDSをやりたいなら、必要なのは正則化ではなく観測であり、項目数・注釈数を桁で増やす。
- **分割設計は「厳密さ」の方向に直す。**  
  - テストはロックし、**テストの正解は専門家ゴールドで固定**する。  
  - Gold24を「アンカー」に使うなら、アンカーはテストから分離しつつ、**64クラス被覆（少なくとも主要クラス被覆）**を満たすよう再設計する。  
  - Cal55で温度だけをいじる前に、**そもそも学習が成立するクラス被覆**を保証する。被覆がない時点でキャリブレーション以前である。

このv14は「シンプル志向」を掲げながら、実際には**最もデータ非効率な場所（64×64混同行列）に複雑さを押し込んだ**。直すべきは正則化ではない。**クラス設計・ゴールド設計・評価設計**である。
