# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
このv9設計案は**現状のまま採用すべきではない**。理由は明確で、(1) 6爻分解の結合式が定義と矛盾しており数学的に破綻している、(2) 「注釈者分布を予測する」という再定義と「6爻独立」モデルが整合せず分布品質（NLL/KL）で必ず崩れる、(3) 目的関数・拒否判定・soft label集約が恣意的で、評価がモデル都合に最適化されるからである。採用するなら、**ラベル生成（注釈モデル）と予測モデルを分離**し、**64卦の同時分布を直接学習**する構成へ作り替える必要がある。

---

### 批判的分析

#### 1) 論理的整合性：結合式が誤りである
- Claudeは `p_j(x) = P(爻j=陽|x)` と定義している。このとき、爻が条件付き独立なら  
  **`P(y|x) = ∏_j p_j(x)^{bit_j} (1-p_j(x))^{1-bit_j}`** で完結する。  
  ここに **`prior(y)` を掛けるのは二重計上であり誤りである**。`p_j` は既に事後確率で、事前を内包しているからである。
- `prior(y)` を入れたいなら、`p_j(x)` を「尤度」側（例：`P(x|bit_j)` や対数尤度比）として定義し直す必要がある。現案は定義と式が矛盾している。

#### 2) 論理的整合性：目的「注釈者分布」とモデル表現が噛み合っていない
- 「注釈者分布（soft label）を予測する」と言いながら、モデルは **6本の周辺確率しか学習しない**。周辺が合っても **64卦の同時分布は合わない**。注釈者の迷いは「特定の2〜3卦に集中する」という**相関した不確実性**として現れるが、独立分解はそれを表現できない。
- 独立分解は不確実性を「各爻の不確実性の直積」に拡散する。結果として、注釈者が選ばない組合せにまで確率を撒き、**NLL/KL/Brierで必ず劣化**する。これは表現能力の限界であり、データ量で解決しない。

#### 3) 実現可能性：実装はできるが、成功条件が定義されていない
- 6本二値モデル、クロスフィット、校正、拒否判定は実装可能である。しかし「目標値なし、データから決定」はプロジェクト管理として破綻である。**停止条件がない設計は永遠にチューニングが続く**。
- 工数240hの配分も不適切である。ボトルネックはモデルではなく、注釈方針・注釈者のばらつき・再現性・ゴールドの定義である。ここが曖昧なままモデル工程に工数を積むのは失敗の典型である。

#### 4) 新規性の真偽：新規性はない
- soft label（分布教師）、拒否（selective classification）、クロスフィット、proper scoring rule（NLL/Brier）は定番である。
- 6爻分解は本質的に **ECOC（誤り訂正出力符号）の最短符号**であり、分類設計として既知である。しかも符号長6は冗長性ゼロで、誤り訂正の利点は弱い。

#### 5) スケーラビリティ：スケールすると欠点が増幅する
- データが増えるほど、64クラス直学習や構造化モデルが強くなる。6爻独立は上限性能が低く、スケールしても頭打ちになる。
- 「注釈者分布」をターゲットにする以上、注釈者母集団が変わると目的分布が変わる。これは**データ拡大で悪化する分布シフト**である。

#### 6) 反例・エッジケース：破綻が確定しているケース
- **多峰性**：注釈者が「卦Aか卦B」で割れる（2峰）とき、独立分解はA/B以外の組合せにも確率を配る。上位候補が汚染され、Top-5再現率が落ちる。
- **系統的注釈者バイアス**：特定注釈者が一貫して同系統の卦へ寄せる。`w(r)`だけでは補正できない。混合すると分布が歪む。
- **priorがゼロ**：未出現卦に`prior(y)=0`を置けば「未出現卦も確率ゼロにならない」という主張は即座に偽になる。
- **確率の端**：二値モデルが0/1へ飽和すると、結合後の64卦分布が不連続になり校正不能になる。

---

### Claudeの意見への反論/修正

- 正しい点：  
  - 「真の卦」ではなく分布として扱う問題再定義は、**注釈が本質的に割れる**タスクでは妥当である。  
  - クロスフィットでOOFを作り、閾値・校正を訓練内で閉じる方針は正しい。
  - 分布品質をNLL/Brier/KLで測るのも正しい。

- 誤り・甘さ：  
  - **結合式が定義と矛盾**している（前述）。これは設計の中核の誤りである。  
  - 「希少卦でも各爻は十分な出現頻度」は一般に成り立たない。データ収集が偏れば爻も偏る。希少性が消える保証はない。  
  - Hamming距離コストは「正しさ」の代理にならない。これは**評価したい価値判断の放棄**である。採用するなら、なぜその距離が業務価値に一致するかを仕様として固定せよ。  
  - `β`を「恣意的固定は禁止」と言いながら、モデル適合で最適化するのは別の恣意性である。`β`は注釈スキームの校正パラメータであり、モデル都合で動かす設計は目的の一貫性を壊す。  
  - フォールバック（Auto率<30%ならc_uを下げる等）は意思決定理論ではない。数値を動かして見かけの指標を整えるだけである。

---

### より正確な見解

1) **まず「分布の定義」を固定せよ**  
「注釈者分布」を目的にするなら、その分布は「現行注釈者プールの癖」を含む。これは仕様として受け入れるか、受け入れないなら「潜在真値（専門家合意）」へ目的を戻せ。中途半端が最悪である。

2) **ラベル集約は“重み付け”ではなく“注釈モデル”でやれ**  
`w(r)=exp(β(r-3))`は雑である。必要なのは以下である。  
- 64卦の潜在変数 `z` を置き、注釈者ごとの混同行列（または簡約版）で `P(annot|z, annotator)` を学習する。  
- 評点`r`は「その注釈の温度/集中度」を変える観測変数として組み込む。  
これで初めて「soft label」が意味を持つ。

3) **予測モデルは64卦分布を直接学習せよ（独立分解は捨てる）**  
- `q(z|annotations)`（注釈モデルの事後）を教師分布として、64クラスの交差エントロピーで学習する。これが「分布予測」の最短距離である。  
- 6爻の恩恵が欲しいなら、独立ではなく **構造化** にせよ（例：爻の対相互作用を持つエネルギーモデル、あるいは上卦/下卦→爻の階層）。「独立」は性能上限を固定するだけである。

4) **拒否（ask）はコストで決めよ。指標で弄るな**  
`c_u`は「人に聞くコスト」であり、A/Bや運用要件から固定する。固定できないなら、coverage-risk曲線を出して意思決定者に選ばせよ。モデル側でAuto率を調整する設計は責任転嫁である。

5) **評価はベースラインと不確実性を含めて固定せよ**  
- ベースライン：`prior`のみ、単純64クラス、上卦/下卦階層。これに勝てない設計は破棄である。  
- 指標：NLL/Brierに加えて、selective risk（拒否込みのリスク）を採用し、テスト60の分散を区間で出せ。単発値の比較は誤差で結論が反転する。

以上。Claude案の方向性（分布＋拒否＋リーク対策）は評価するが、中核である6爻独立分解と結合式は破綻している。採用版として通すなら、そこを捨てて「注釈モデル＋64分布直学習」に置き換えよ。
