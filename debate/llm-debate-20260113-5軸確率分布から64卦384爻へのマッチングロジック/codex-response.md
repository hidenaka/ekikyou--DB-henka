# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
Claude案（卦ごとの理想分布＋コサイン類似度＋卦決定後に爻を一般マッピング）は設計として破綻している。なぜなら「理想分布」の根拠が検証不能で、確率分布比較として不適切な指標を使い、さらに爻を卦から独立に選ぶ二段階設計が易経側の意味構造と説明可能性を同時に壊すからである。要件が「384への決め打ち」なら、この方式の採用は誤りである。

---

### 批判的分析

#### 1. 論理的整合性
- **5軸→384の識別は情報量が不足である。** timeframeは6択1問、relationshipは多選1問で解像度が低く、残りも比率に圧縮される。異なる多数の（卦×爻）が同一の5軸分布を取り得るため、安定な順位付けは成立しない。
- **「理想分布」を卦に付与する前提が未定義である。** 乾為天={拡大0.7…}のような割当は、採点者の解釈に依存する。解釈規約（ルーブリック）なしに数値だけ置くと、体系は内的整合性を持たない。
- **二段階（卦→爻）の独立選択は誤りである。** 爻の意味は卦に条件付く。卦と無関係に「timeframe/agency/emotionで初爻〜上爻」を決めると、同じ爻段階でも卦ごとの文脈差を吸収できず、説明文が必ず矛盾する。
- **軸の二重使用で重み付けが崩壊する。** 卦決定にtimeframe/agency/emotionを使い、さらに爻決定でも同じ軸を使うと、その3軸が実質的に過重になる。これは設計原理ではなく偶然のバイアスである。

#### 2. 実現可能性
- **実装は容易だが品質保証は不可能である。** 類似度計算自体は数百行で終わる。一方、64卦（または384爻）に5軸の分布を与える作業は「本体」であり、ここが最大コストである。ここを雑に作ると出力がランダム占いになる。
- **「運用データで重み調整」は目的関数が不正である。** KPIが自己納得度中心だと、最適化はユーザー迎合（バーナム効果）へ収束する。これは予測でも診断でもなく、満足度最大化の作文生成器になる。

#### 3. 新規性の真偽
- **新規性はない。** 「プロトタイプ（理想分布）に対する距離で最近傍分類」は既存手法そのものである。易経ドメインを載せ替えただけで、方法論として新しくない。

#### 4. スケーラビリティ
- **保守が崩壊する。** 軸を1つ増やす、選択肢を変える、設問の意味を調整するたびに、全卦（全爻）の理想分布を再定義する必要が生じる。これは運用で耐えない。
- **版管理の必須化を招く。** v4→v5で分布定義が変わると、同一ユーザーの再テスト比較が無意味になる。診断としての連続性が壊れる。

#### 5. 反例・エッジケース
- **「わからない」が高確信度になる破綻。** timeframeをone-hotで扱うと「わからない」はエントロピー0でconfidence=1になる。情報が無い選択が最も確信度が高いという矛盾が発生する。
- **混合状態を“不確か”と誤判定する破綻。** 感情や変化性質が混ざるのは現実の状態であり、エントロピーが高い=測定が不確かではない。これをconfidence低として追加質問で単一感情へ強制すると、v4の「混合状態保持」原則と正面衝突する。
- **同点・近接が多発しTop-5が恣意化する。** 軸数と解像度が低く、距離が同点になりやすい。タイブレーク規則を入れた瞬間に「数学」ではなく「作者の好み」になる。

#### 6. 代替案との比較
- **より優れた設計は存在する。** 少なくとも「確率分布同士の距離」「卦と爻の条件付きモデル」「欠損（わからない）の扱い」を備えた方式は、Claude案より一貫性・検証性・説明可能性が高い。

---

### Claudeの意見への反論/修正
- **正しい部分**: 「卦ごとに参照プロファイルを用意して上位候補を出す」という枠組みは、実装容易性と説明可能性（寄与度分解）に利点がある。懸念として挙げた「理想分布の決め方」「爻マッピングの恣意性」も核心を突いている。
- **誤り（致命傷）**:
  - **コサイン類似度採用は誤りである。** 確率分布比較としての幾何が不適切で、スコアの意味が崩れる。特に「%表示」や「差分12pt」の解釈が成立しない。
  - **爻を卦から独立に決める設計は誤りである。** 易経側の意味論に反し、説明文が整合しない。
  - **重みを運用データで調整する方針は甘い。** 何を正解とみなして最適化するかが欠落している。自己納得度で最適化すると「当たった感」を最大化するだけで、モデル妥当性が消える。

---

### より正確な見解
1) **要件を正す**  
「5軸から384を一意に決める」は誤りである。正しい要件は「384の事後確率（ランキング）を出す」「不確実さを表示する」である。決め打ちは捨てるべきである。

2) **スコアリングを“分布に適した”形に替える**  
- 各（卦×爻）をクラス \(k\) とし、各軸の参照分布 \(q_{k,a}\) を持たせる。  
- ユーザー分布 \(p_a\) との距離は **Jensen–Shannon距離** や **交差エントロピー** のような分布向け指標を使う。  
- 総合スコアは \(Score(k)=\sum_a r_a \cdot f(p_a,q_{k,a})\) とし、\(r_a\) は「測定の信頼性」である。エントロピー（混合度）を \(r_a\) に流用するのは誤りである。

3) **爻は“卦に条件付けて”決める**  
- 二段階にするなら \(P(爻 \mid 卦, 入力)\) を卦ごとに持つ。一般マッピングは禁止である。  
- 実務的には「384を直接ランキング」する方が一貫する（卦→爻の独立性問題を消す）。

4) **欠損の扱いを明確化する**  
- timeframeの「わからない」はカテゴリではなく欠損として扱い、その軸の重み \(r_{timeframe}=0\) に落とす。これをやらない限り、論理は必ず破綻する。

5) **理想分布の作り方を“検証可能な作業”に落とす**  
- ルーブリック（各軸・各カテゴリに対応する易経記述の根拠規則）を先に作り、LLM生成＋専門家レビューで \(q_{k,a}\) を作る。数値の「雰囲気置き」は禁止である。  
- その上で、Top-5提示と寄与度説明は成立する。

以上が「本質を外さず、実装でき、説明が崩れない」設計である。
