# Codex (OpenAI GPT-5.2) の批評

### 結論（最初に明言）
現状の事例DBは「64卦を一度は埋めた」に過ぎず、**網羅性は達成していない**。地理・時代・ソース・爻位・卦×爻の分布が歪んでおり、一般化して使える「変化ロジックDB」としての代表性が欠落している。

### 批判的分析
1. **論理的整合性**
   - 「64卦100%カバー」は網羅性の根拠にならない。64個の箱に1件ずつ入れても100%であり、多様性も偏りも保証しない。
   - 「384組平均33件」は評価指標として誤りである。平均はロングテールを隠し、薄いセル（数件しかない組）という欠損を覆い隠す。網羅性は最小値・下位分位・閾値未達セル数で測るべきである。
   - 「坤が少ない」「5爻が過剰」という断定は、期待分布（何を基準に“少ない/過剰”と言うか）を定義していないため評価として成立しない。これは分析ではなく感想である。

2. **実現可能性**
   - 国際・歴史事例の追加は、収集よりも「翻訳・権利処理・同一基準での再注釈・品質管理」がコストの本体である。件数を増やすだけで品質は崩壊する。
   - ニュース中心のまま増やすと偏りは固定される。量を増やしても網羅性は増えない。サンプリング設計なしの追加収集は無意味である。

3. **新規性の真偽**
   - 「大量事例に易経ラベル」は題材としては新しいが、「64卦を埋めた」「偏りがある」は既存のデータ評価の初歩であり新規性ではない。
   - 新規性を支えるのはラベル定義の再現性（注釈規約、注釈者間一致、バージョニング）である。ここが示されていない時点で研究資産として弱い。

4. **スケーラビリティ**
   - 件数が増えるほどラベル一貫性が壊れる。人手解釈で卦・爻を割り当てる設計は、合意規約と一致率がない限りスケールしない。
   - 72%がニュースは重複（同一事件の派生記事）を大量に含む構造である。見かけの件数が増えても有効サンプルは増えない。

5. **反例・エッジケース**
   - 1事例が複数の卦・複数爻に当てはまるケースは必ず発生する。単一ラベル前提は破綻する。
   - 初爻〜二爻の「芽生え・内面の整え」などはニュース断片では記録されにくい。爻位分布の歪みはデータ源の構造欠陥である。
   - 国際化すると制度・文化が変わり、同じ事象でも解釈が変わる。規約が弱いまま国際データを混ぜるとノイズになる。

6. **代替案との比較**
   - 追加収集より先に「網羅性の定義」と「評価ダッシュボード」を作るべきである。384セルのうち閾値未達セル数、下位10%セルの件数、ジニ係数/エントロピーなどで偏りを固定指標化する。
   - 「巨大で偏ったコーパス」と「小さく均衡した検証セット」を分離せよ。前者は検索・発想支援、後者はロジック検証・学習用である。これが最小コストで精度を上げる。

### Claudeの意見への反論/修正
- 「64卦100%カバー」は事実でも、網羅性評価としては無意味である。ここを強調した時点で議論の軸がずれている。
- 「坤が少ない」「5爻過剰」は基準分布がないため断定が誤りである。正しくは「分布が歪んでいる」で止め、目的に照らして問題度を決めるべきである。
- 「平均33件」は指標として不適切である。網羅性の焦点は平均ではなく「薄いセルの厚み」である。
- 「坤追加? 国際? 1爻2爻? 歴史?」は施策が雑である。サンプリング方針、重複排除、注釈規約、品質指標がない追加はDBを巨大なノイズにするだけである。
- ただし、地理・年代・ソース・爻位の偏りを定量で出した点は正しい。問題発見まではできている。

### より正確な見解
このDBの現状は「日本の近現代ニュース中心の易経事例集」であり、「易経の変化ロジックを一般化して検証できる網羅DB」ではない。網羅性を成立させるために必要なのは件数追加ではなく、(1) 対象母集団の定義、(2) 多次元（卦×爻・地理・年代・ソース・ドメイン）での最低要件と欠損管理、(3) ニュース偏重を壊すソース設計と注釈品質の固定（規約＋一致率＋版管理）である。これを欠いたまま件数を増やしても、網羅性は永久に達成しない。
