# LLM Debate: 六十四卦マッピングv7-同時スコアリング+soft-label

## 議題
六十四卦マッピングv7-同時スコアリング+soft-label

## Claude (Anthropic) の見解
## 改善計画v7 - 同時スコアリング方式

Codex v6批評の全修正点を反映。

### v6からの主要修正

1. **独立積 → 8×8同時スコア**: 上卦×下卦の独立仮定を廃止、64卦を直接スコア
2. **単一正解 → soft label**: 複数専門家の投票分布をゴールドに
3. **常時Top-k → 不確実時のみ**: エントロピー/マージンで判定、確実時は自動確定
4. **校正を必須化**: 温度スケーリング+ECE検証
5. **工数を現実的に**: 156h→260h（注釈設計工程を含む）

### アーキテクチャ

Stage 1: 候補生成（Retrieval）
- 類似事例検索で20-50候補に絞る

Stage 2: 同時スコアリング（Joint Scoring）
- LLMで8×8ロジット行列を出力
- 類似検索スコアと重み付き統合（α=0.7）
- 温度スケーリングで校正

Stage 3: 不確実性判定
- エントロピー/Top-1マージンを計算
- 確実（top1_prob>0.4 & margin>0.2）→自動確定
- 不確実（entropy>0.7 or margin<0.1）→ユーザー関与

Stage 4: 条件付きユーザー関与（不確実時のみ）
- Top-k候補提示
- 本質八卦フィルタ（15卦絞り込み）
- 追加質問

Stage 5: 64卦確定 → 爻判定

### soft labelによるゴールドセット

3名の注釈者が独立に妥当な卦を選択（複数選択可）
各卦に妥当度（1-5）を評価
投票分布を正規化してsoft labelに

評価指標:
- KL Divergence ≤1.0
- Top-k Overlap ≥70%
- nDCG@10 ≥0.6
- ECE ≤0.15
- Fleiss kappa ≥0.4

### 工数見積もり: 260h

Phase 1 設計: 40h
- アーキテクチャ、プロンプト、ルーブリック策定

Phase 2 パイロット: 60h
- 注釈者トレーニング、50件パイロット、一致度分析

Phase 3 ゴールドセット: 120h
- 300件×3名注釈、品質監査、調停、soft label生成

Phase 4 モデル構築: 40h
- 実装、評価・調整

### フォールバック

- Fleiss kappa<0.3: ルーブリック再設計
- nDCG@10<0.4: 類似検索重み増加
- 自動確定率<50%: 閾値緩和
- ECE>0.25: 別の校正手法検討

## Codex (OpenAI GPT-5.2) の批評
### 結論（最初に明言）
このv7計画は「方向性だけは改善」だが、現状の仕様は未定義と恣意的パラメータだらけで、**そのまま実装しても信頼できる六十四卦マッピング器にならない**。最大の欠陥は、**確率・不確実性・校正を前提にしながら、確率が何から導かれる量かを定義していない**点と、**評価指標／合意指標の選択が誤っている**点である。

### 批判的分析
#### 1) 論理的整合性
- **Stage 1「20–50候補に絞る」**と、Stage 2「**8×8ロジット行列(=64全件)を出力**」が矛盾している。64を同時スコアするなら候補絞りは前段の“計算削減”として成立しない。絞るなら8×8行列という表現自体が崩れる。
- **類似検索スコアとロジットの加重統合(α=0.7)**は数学的に不整合である。検索スコアは通常「類似度」であり、ロジットは「対数オッズに比例する量」である。単純線形結合は尺度が揃っていないため意味がない。統合は学習で決めるか、少なくともスコアを同一確率空間へ写像する必要がある。
- **不確実性判定の閾値が定義不備**である。`entropy>0.7`は対数の底（bits/nats）とクラス数に依存し、64分類で0.7は基準として成立しない。`top1_prob>0.4`や`margin>0.2`も根拠が提示されていないため恣意的である。

#### 2) 実現可能性（隠れたコスト含む）
- 「LLMでロジット行列を出力」が**“モデル内部のロジット”**を意味するのか、**“テキストとして数字を出させる”**のかが未定義である。後者ならその数値は確率でもロジットでもなく、**温度スケーリングもECEも数学的根拠を失う**。
- **温度スケーリングは検証用の十分な独立データが必須**である。300件規模でECE≤0.15のような閾値運用は統計的に不安定になる。校正の良否を判定するにはブートストラップ等で信頼区間を出す設計が必要である。
- 工数見積もり260hは「注釈作業」中心の見積もりで、**ルーブリックの反復改訂、注釈者のドリフト管理、検索DB整備、評価の再現性確保、誤判定の原因分析**が抜けている。ここが実務コストの本体である。

#### 3) 新規性の真偽
- これは**新規手法ではない**。RAG（類似検索）＋ reranking（同時スコアリング）＋ soft label（ラベル分布学習）＋ selective prediction（不確実時のみ人間介入）＋ post-hoc calibration（温度スケーリング）は既存の定石の組合せである。
- 「8×8同時スコア」は表現の違いであり、実体は**64クラス分類／ランキング**である。新規性は「六十四卦」という応用領域にしかない。

#### 4) スケーラビリティ
- 注釈は**線形に増える**。しかも“複数選択＋1–5妥当度”は認知負荷が高く、スケールすると品質が落ちる。
- 検索ベースは事例が増えるほど強くなる一方で、評価分割を誤ると**検索リークで数字だけ良くなる**。スケール時ほど実験設計が難しくなる。
- 不確実性判定が不安定なまま運用すると、**自動確定の誤り**か**ユーザー介入の過多**のどちらかに必ず偏る。閾値調整で場当たり的に動かす設計はスケールで破綻する。

#### 5) 反例・エッジケース
- 入力が「複数の卦に同程度に当てはまる」ケースは構造的に存在する。soft labelはその事実を表現するだけで、**単一の“正解”に収束させる根拠を提供しない**。
- レア卦（事例が少ない卦）は検索でも学習でも弱くなり、**頻出卦への吸い寄せ（prior崩壊）**が起きる。
- 「本質八卦フィルタで15卦に絞り込み」は、正解がフィルタ外にあるケースで**確実に破綻**する。フィルタを入れるなら、漏れ率を定量化し、漏れたときの救済経路を設計する必要がある。

#### 6) 代替案との比較（より優れた設計が存在する）
- 本件は本質的に「分類」ではなく**推薦（ranking）＋対話による追加情報取得**である。最初からTop-k提示を標準にし、ユーザー価値（納得感・説明可能性）を最適化する設計の方が目的に合致する。
- 不確実性はエントロピー閾値ではなく、**risk–coverageで目標誤り率を満たす選択的予測**、または**conformal predictionで“保証付きの候補集合”**を返す方式が上位互換である。
- 検索スコア統合は固定αではなく、**学習されたスタッキング（例：ロジスティック回帰/GBDT）**か、logit空間で整合する**事前分布（検索）＋尤度（モデル）**の形に落とすべきである。

### Claudeの意見への反論/修正
- 正しい修正点はある。独立積を捨てて64を直接扱う、soft labelを導入する、確実時のみ自動確定にする、校正を必須化する、工数を増やす。ここは妥当である。
- しかし致命的な甘さが残る。
  - **Fleiss kappa ≥0.4は誤り**である。今回の注釈は「複数選択＋順序尺度(1–5)」であり、Fleiss kappa（単一カテゴリの名義尺度前提）に適合しない。指標選定が間違っている。
  - **entropy/margin/top1_probの閾値は根拠ゼロ**である。単なる思いつきの数値で運用を語っている。これは研究計画ではなく占いである。
  - **α=0.7固定**は論外である。尺度の違う量を固定重みで足す設計は、改善計画ではなく劣化装置である。
  - 「ECE検証」も、ロジットの定義とデータ量の設計がない以上、**検証手順が成立しない**。

### より正確な見解
- この議題の本質は「六十四卦に唯一の正解がある」ではなく、**状況記述→卦の妥当度分布を返し、必要なら追加質問で分布を収束させる**問題である。よって目標は「当てる」ではなく**誤確定を抑えつつ納得度を最大化する**である。
- 成立するv7は次の要件を満たす必要がある。
  1) **確率の定義を固定**：ロジットはモデル内部量（またはそれに整合するスコア）に限定し、テキスト出力の“自己申告スコア”を排除する。  
  2) **統合は学習で決める**：検索スコアは確率空間へ写像し、結合重みは検証データで最適化する（固定αを廃止）。  
  3) **不確実性は目標誤り率で設計**：閾値は任意数値ではなく、検証セットで「誤確定率≤X%」を満たすcoverageを最大化して決める（risk–coverage曲線）。  
  4) **注釈設計を現実に合わせる**：多ラベル＋順序尺度に適合する合意指標（例：Krippendorffのα）と、評価指標（nDCG/Brier/対数損失）を採用し、注釈者ごとの尺度差を補正する。  
  5) **“15卦フィルタ”は原則禁止**：入れるなら漏れ率を定量化し、漏れ時に必ず64へ戻す救済経路を設ける。  

この修正を入れた上で初めて、v7は「改善計画」として成立する。現状案は“それっぽい単語の羅列”であり、厳密性の基準を満たさない。


## 統合分析
### 共通点
（Claudeによる分析が必要）

### 相違点
（Claudeによる分析が必要）

### 結論・推奨
（Claudeによる最終まとめが必要）

---
*生成日時: 2026-01-14T00:51:04.986Z*
